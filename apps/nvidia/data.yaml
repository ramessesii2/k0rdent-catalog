tags:
    - AI/Machine Learning
    - Drivers and plugins
title: "NVIDIA GPU Operator"
summary: "NVIDIA GPU Operator creates/configures/manages GPUs atop Kubernetes."
logo: "./assets/GPUoperator-cropped.png"
created: "2025-03-12T08:16:55Z"
description: |
    The NVIDIA GPU Operator for Kubernetes is a powerful tool that simplifies the management of GPUs
    in your Kubernetes clusters. It automates the deployment and configuration of all the necessary
    software components to enable GPUs, making it easier to run GPU-accelerated workloads like AI/ML
    training and high-performance computing.
support_link: https://docs.nvidia.com/datacenter/cloud-native/partner-validated/latest/k0rdent.html
install_code: |
    ~~~bash
    helm install gpu-operator oci://ghcr.io/k0rdent/catalog/charts/gpu-operator-service-template \
      --version 24.9.2 -n kcm-system
    ~~~
verify_code: |
    ~~~bash
    kubectl get servicetemplates -A
    # NAMESPACE    NAME                          VALID
    # kcm-system   gpu-operator-24-9-2           true
    ~~~
deploy_code: |
    Tested `ClusterDeployment` in AWS:
    ~~~yaml
    apiVersion: k0rdent.mirantis.com/v1alpha1
    kind: ClusterDeployment
    metadata:
      name: aws-example-cluster
    spec:
      template: {{ aws_standalone_cp }}
      credential: aws-credential
      config:
        clusterLabels:
          type: aws
          group: demo
        controlPlane:
          instanceType: t3.small
        controlPlaneNumber: 1
        publicIP: false
        region: eu-central-1
        worker:
          # Small AWS instance with NVIDIA GPU
          instanceType: g4dn.xlarge
          # AMI Catalog - Community AMIs:
          #  Find region specific AMI ID with title:
          #  "ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server"
          #  eu-central-1: ami-0162f0739222cca1c, us-east-2: ami-00eb69d236edcfaf8, ap-south-1: ami-0b738b0c888af81f7
          amiID: "ami-0162f0739222cca1c"
          imageLookup: {org: "", format: "", baseOS: ""}
          rootVolumeSize: 100
        workersNumber: 1
    ~~~

    Tested `ClusterDeployment` in Azure:
    ~~~yaml
    apiVersion: k0rdent.mirantis.com/v1alpha1
    kind: ClusterDeployment
    metadata:
      name: azure-example-cluster
    spec:
      template: {{ azure_standalone_cp }}
      credential: azure-credential
      config:
        clusterLabels:
          type: azure
          group: demo
        controlPlaneNumber: 1
        workersNumber: 1
        location: "westus"
        subscriptionID: SUBSCRIPTION_ID_SUBSCRIPTION_ID # Enter the Subscription ID used earlier
        controlPlane:
          vmSize: Standard_A4_v2
        worker:
          image:
            marketplace:
              publisher: "Canonical"
              offer: "0001-com-ubuntu-minimal-jammy"
              sku: "minimal-22_04-lts"
              version: "22.04.202502270"
          rootVolumeSize: 32
          # Small Azure instance with NVIDIA GPU
          vmSize: Standard_NC4as_T4_v3
    ~~~

    Operator deployment:
    ~~~yaml
    apiVersion: k0rdent.mirantis.com/v1alpha1
    kind: MultiClusterService
    metadata:
      name: gpu-operator
    spec:
      clusterSelector:
        matchLabels:
          group: demo
      serviceSpec:
        services:
        - template: gpu-operator-24-9-2
          name: gpu-operator
          namespace: gpu-operator
          values: |
            gpu-operator:
              operator:
                defaultRuntime: containerd
              toolkit:
                env:
                  - name: CONTAINERD_CONFIG
                    value: /etc/k0s/containerd.d/nvidia.toml
                  - name: CONTAINERD_SOCKET
                    value: /run/k0s/containerd.sock
                  - name: CONTAINERD_RUNTIME_CLASS
                    value: nvidia
              # optionally, create DCGM-Exporter ServiceMonitor
              dcgmExporter:
                serviceMonitor:
                  enabled: true
                  interval: 15s
                  honorLabels: true
                  additionalLabels: {}
    ~~~
